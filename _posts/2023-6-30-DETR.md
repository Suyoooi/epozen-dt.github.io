---
title: "DETR"
last_modified_at: 2023-06-30
author: Gun-ha, KANG
---

> 이번 포스팅에서는 *DETR**에 대한 내용을 공유해보려고 합니다.


# **DETR**


> **개요**  

* **객체탐지 목표**

  + BoundingBox 및 Label 예측

* **기존 객체탐지의 detection**

  + 이미지 내 고정된 지점마다 다양한 scale, aspect ratio를 가진 anchor 생성
  + anchor 기반으로 생성한 예측 BoundingBox 와 GroundTruth 를 Matching
  + Many-to-one
    + 하나의 GT 에 다수의 BBox 매칭
    + NMS 와 같은 후처리 과정 필수

* **DETR (DEtection TRansformer) detection**
  + 객체탐지를 direct set prediction 로 간주하고 해결
    + BBox 와 Category set 을 예측하는 Task
  + Hand-crafted anchor 사용하지 않음
  + one-to-one
    하나의 GT 에 하나의 BBox 매칭



## **Method**

> **DETR pipeline**
 
앞에서 얘기한 기존의 객체탐지의 indirect 한 방법들과 중복 예측을 피하기 위한 target box를 정하는 후처리 단계를 간소화하는 방법을 제안합니다.

+ Bipartite Matching (이분매칭)
  + set loss function을 사용하여 end-to-end 학습 수행
+ Transformer Encoder-Decoder Architecture
  + 병렬 처리 가능

![그림1](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/b919a969-85f2-4175-93a3-14a84af65b73)

> **DETR Architecture**

+ Predicted 된 box와 GT 간의 unique한 매칭을 하기 위한 set prediction loss를 사용
+ set of objects를 예측하고 그들의 관계를 모델링하는 architecture 사용
  + CNN Backbone(ResNet) + Transformer encoder-decoder + FFN(Feed Forward Network)

![그림2](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/42931823-89c6-4b0c-a861-2963478322ad)

+ 해당 수식은 예측 BBox와 GT 사이의 matching cost를 최소화하는 permutation σ 를 탐색
  + 고정된 크기의 N 개의 prediction만 수행함으로써, 수많은 anchor 생성과정을 우회
  + Hungarian 알고리즘 이용 

![그림3](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/a8709b04-1537-4d12-916e-5b03d214b5cf)

+ 해당 수식은 permutation σ 로 매칭된 BBox와 GT 사이의 loss를 계산하는 식
  + Class loss: prediction에 대한 negative log-likelihood 계산
  + Box loss: L1 loss + GIoU 결합한 식으로 계산

![그림4](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/1c1ed5fb-24a6-49e6-8dd5-5407815e2d91)


> **학습 과정**

+ CNN Backbone 에서 피쳐맵 추출
+ Positional Encoding 추가
+ Object queries 생성
+ 트랜스포머 인코더의 인코더 메모리 출력
+ 트랜스포머 디코더에 의한 출력 임베딩
+ Class head 별 클래스 예측
+ BBox head 에 의한 BBox 예측
+ Hungarian Matching에 의한 GT 매칭 예측 (L_match)
+ 손실 계산 (L_hungarian)


## **Experiments**

> **Faster R-CNN 과의 비교**

+ COCO dataset을 기준으로 성능 비교
  + Small size의 Object에 대해서 약한 성능을 보임 
  + 외의 size에서는 DETR이 더 좋은 성능을 보임
    
+ 전반적으로 Faster R-CNN과 비슷한 수준의 성능을 보임

![그림5](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/4b1bad9a-1a30-45b3-8ee9-56478412a95e)

> **Number of Encoder layers**

+ Encoder 구조는 global한 scene reasoning을 수행해서 object 들을 구별
+ Encoder layer 를 많이 사용할수록 성능 향상

![그림6](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/1e2aa8af-b61e-4cb4-bd24-e7939a0b65a4)

+ Encoder의 attention map을 시각화

![그림7](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/1ec1f0ac-ffe6-4543-9b16-70437c61ff6a)



> **Number of Decoder layers**

+ Decoder 또한 충분한 수의 layer를 사용해야 함
+ 각각의 Extremities (말단 정보) 사용해서 클래스를 잘 구분하고 boundary 또한 잘 얻게 됨

![그림8](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/f958f8ad-a7f4-4330-b8de-a43e9f79f9e2)

+ Decoder의 attention map을 시각화

![그림9](https://github.com/epozen-dt/epozen-dt.github.io/assets/92897860/a08397eb-7bae-407a-8f50-7896267fa202)


> **참고 자료**  

* [[1] End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)  

---

<details>
  <summary><b>Contact</b></summary>

<b>Author. </b>KangGunha

<b>Email. </b>zxcvbnm9931@epozen.com

</details>









